{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "Given (user, music, format(optional)) tuple, predict the rating that the user will give to the music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful fields:\n",
    "# |name       | possible value  | analysis\n",
    "# \"overall\":    1 - 5 (int)\n",
    "# \"verified\":   True / False      (Don't know meaning yet)\n",
    "# \"reviewerID\": \"A1SJL3JBBILJ66\"\n",
    "# \"asin\": \"     B0018CGCR4\"       (music ID)\n",
    "# \"format\":     \" MP3 Music\"      86.44%\n",
    "#               \" Audio CD\"       6.37%\n",
    "#               \"\" (undeclared)   6.95%\n",
    "#               \" Vinyl\"          .2%\n",
    "#               (others)          <.04%\n",
    "# \"reviewText\": \"THANK YOU\"       .09% users doesn't provide reviewText, indcicate as \"\"\n",
    "# \"summary\":    \"Five Stars\"      .002% users doesn't provide summary, indcicate as \"\"\n",
    "# \"image\":      0 (int)           .107% users provide image\n",
    "#                                 indicate number of images provided in the review\n",
    "# \"vote\":       0 (int)           4.48% reviewers are voted by others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training/validation sets... Finish\n",
      "Size of train      set: 140000\n",
      "Size of validation set: 10000\n",
      "Size of test       set: 19781\n",
      "\n",
      "CPU times: user 4.72 s, sys: 147 ms, total: 4.86 s\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# constrain: ensure each user/data appear at least 4 times in the training set\n",
    "print('Building training/validation sets... ', end='')\n",
    "\n",
    "f = open(\"./train.json\", 'rt', encoding=\"utf8\")\n",
    "\n",
    "train = [eval(l) for l in f]\n",
    "valid = train[140000:]\n",
    "train = train[:140000]\n",
    "\n",
    "f = open(\"./test.json\", 'rt', encoding=\"utf8\")\n",
    "test = [eval(l) for l in f]\n",
    "\n",
    "print('Finish\\n'\n",
    "      'Size of train      set: %d\\n'\n",
    "      'Size of validation set: %d\\n'\n",
    "      'Size of test       set: %d\\n' % (len(train), len(valid), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.0: Naivest Baseline, Constant\n",
    "Find the constant $\\theta$ that mimize the MSE of the train set as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49839595183673463"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = np.ones((len(train), 1))\n",
    "y_t = [d['overall'] for d in train]\n",
    "X_v = np.ones((len(valid), 1))\n",
    "y_v = [d['overall'] for d in valid]\n",
    "\n",
    "mod = linear_model.LinearRegression()\n",
    "mod.fit(X_t,y_t)\n",
    "\n",
    "print(metrics.mean_squared_error(mod.predict(X_v), y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.1 : Naive Solution 1, Global Average\n",
    "Predict Value = $\\theta_0$ + $\\theta_1$ * (average rating that the user gives out) + $\\theta_2$ * (average rating that the music receives)\n",
    "\n",
    "Use linear regressor to optimize $\\theta_0$, $\\theta_1$ and $\\theta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 5,\n",
       " 'verified': True,\n",
       " 'reviewerID': 'A1SJL3JBBILJ66',\n",
       " 'asin': 'B0018CGCR4',\n",
       " 'reviewText': 'THANK YOU',\n",
       " 'summary': 'Five Stars',\n",
       " 'format': ' MP3 Music',\n",
       " 'vote': 0,\n",
       " 'image': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "users = []\n",
    "items = []\n",
    "for d in train:\n",
    "    r = int(d['overall'])\n",
    "    ratingsPerUser[d['reviewerID']].append(r)\n",
    "    ratingsPerItem[d['asin']].append(r)\n",
    "    users.append(d['reviewerID'])\n",
    "    items.append(d['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRatingsPerUser = defaultdict(int)\n",
    "avgRatingsPerItem = defaultdict(int)\n",
    "for u in ratingsPerUser:\n",
    "    avgRatingsPerUser[u] = np.mean(ratingsPerUser[u])\n",
    "for item in ratingsPerItem:\n",
    "    avgRatingsPerItem[item] = np.mean(ratingsPerItem[item])\n",
    "\n",
    "trainRatings = [int(d['overall']) for d in train]\n",
    "globalAverage = sum(trainRatings) * 1.0 / len(trainRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.700542857142858"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [1,avgRatingsPerUser[datum['reviewerID']],avgRatingsPerItem[datum['asin']]] \n",
    "    return feat\n",
    "X_train = [feature(d) for d in train]\n",
    "y_train = [int(d['overall']) for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod = linear_model.LinearRegression()\n",
    "_ = mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29833395750578445\n"
     ]
    }
   ],
   "source": [
    "X_valid = [feature(d) for d in valid]\n",
    "y_valid = [int(d['overall']) for d in valid]\n",
    "# valid_predictions = mod.predict(X_valid)\n",
    "print(metrics.mean_squared_error(mod.predict(X_valid), y_valid))\n",
    "# sum(valid_predictions == y_valid) /len(y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.2: Naive Solution 2, tf-idf\n",
    "Use the similar approach in hw4:\n",
    "\n",
    "Find tf-idf of reviews, then train a Ridge model to predict the rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Solution\n",
    "Sim users give high rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't prove that user will rate a music he'she never listened as the way he/she will rate a listened music.\n",
    "\n",
    "For example, a user will only rate musics he/she like, so he/she rated every music 5 stars.\n",
    "\n",
    "It is possible that our model will predict that the user will give high ratings to all musics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
