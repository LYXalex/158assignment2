{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "Given (user, music, format(optional)) tuple, predict the rating that the user will give to the music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful fields:\n",
    "# |name       | possible value  | analysis\n",
    "# \"overall\":    1 - 5 (int)\n",
    "# \"verified\":   True / False      (Don't know meaning yet)\n",
    "# \"reviewerID\": \"A1SJL3JBBILJ66\"\n",
    "# \"asin\": \"     B0018CGCR4\"       (music ID)\n",
    "# \"format\":     \" MP3 Music\"      86.44%\n",
    "#               \" Audio CD\"       6.37%\n",
    "#               \"\" (undeclared)   6.95%\n",
    "#               \" Vinyl\"          .2%\n",
    "#               (others)          <.04%\n",
    "# \"reviewText\": \"THANK YOU\"       .09% users doesn't provide reviewText, indcicate as \"\"\n",
    "# \"summary\":    \"Five Stars\"      .002% users doesn't provide summary, indcicate as \"\"\n",
    "# \"image\":      0 (int)           .107% users provide image\n",
    "#                                 indicate number of images provided in the review\n",
    "# \"vote\":       0 (int)           4.48% reviewers are voted by others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training/validation sets... Finish\n",
      "Size of train      set: 140000\n",
      "Size of validation set: 10000\n",
      "Size of test       set: 19781\n",
      "\n",
      "CPU times: user 5.78 s, sys: 205 ms, total: 5.99 s\n",
      "Wall time: 6.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# constrain: ensure each user/data appear at least 4 times in the training set\n",
    "print('Building training/validation sets... ', end='')\n",
    "\n",
    "f = open(\"./train.json\", 'rt', encoding=\"utf8\")\n",
    "\n",
    "train = [eval(l) for l in f]\n",
    "valid = train[140000:]\n",
    "train = train[:140000]\n",
    "\n",
    "f = open(\"./test.json\", 'rt', encoding=\"utf8\")\n",
    "test = [eval(l) for l in f]\n",
    "\n",
    "print('Finish\\n'\n",
    "      'Size of train      set: %d\\n'\n",
    "      'Size of validation set: %d\\n'\n",
    "      'Size of test       set: %d\\n' % (len(train), len(valid), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(pred, actual):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.1 : Naive solution 1, Global Average\n",
    "Predict Value = $\\theta_0$ + $\\theta_1$ * (average rating that the user gives out) + $\\theta_2$ * (average rating that the music receives)\n",
    "\n",
    "Use linear regressor to optimize $\\theta_0$, $\\theta_1$ and $\\theta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin': 'B0018CGCR4',\n",
       " 'format': ' MP3 Music',\n",
       " 'image': 0,\n",
       " 'overall': 5,\n",
       " 'reviewText': 'THANK YOU',\n",
       " 'reviewerID': 'A1SJL3JBBILJ66',\n",
       " 'summary': 'Five Stars',\n",
       " 'verified': True,\n",
       " 'vote': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "users = []\n",
    "items = []\n",
    "for d in train:\n",
    "    r = int(d['overall'])\n",
    "    ratingsPerUser[d['reviewerID']].append(r)\n",
    "    ratingsPerItem[d['asin']].append(r)\n",
    "    users.append(d['reviewerID'])\n",
    "    items.append(d['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexli/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/alexli/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "avgRatingsPerUser = defaultdict(int)\n",
    "avgRatingsPerItem = defaultdict(int)\n",
    "for u in ratingsPerUser:\n",
    "    avgRatingsPerUser[u] = np.mean(ratingsPerUser[u])\n",
    "for item in ratingsPerItem:\n",
    "    avgRatingsPerItem[item] = np.mean(ratingsPerItem[item])\n",
    "\n",
    "trainRatings = [int(d['overall']) for d in train]\n",
    "globalAverage = sum(trainRatings) * 1.0 / len(trainRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.700542857142858"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [1,avgRatingsPerUser[datum['reviewerID']],avgRatingsPerItem[datum['asin']]] \n",
    "    return feat\n",
    "X_train = [feature(d) for d in train]\n",
    "y_train = [int(d['overall']) for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/alexli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = [feature(d) for d in valid]\n",
    "y_valid = [int(d['overall']) for d in valid]\n",
    "valid_predictions = mod.predict(X_valid)\n",
    "sum(valid_predictions == y_valid) /len(y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.2: Naive Solution 2, tf-idf\n",
    "Use the similar approach in hw4:\n",
    "\n",
    "Find tf-idf of reviews, then train a Ridge model to predict the rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.1: Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't prove that user will rate a music he'she never listened as the way he/she will rate a listened music.\n",
    "\n",
    "For example, a user will only rate musics he/she like, so he/she rated every music 5 stars.\n",
    "\n",
    "It is possible that our model will predict that the user will give high ratings to all musics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
