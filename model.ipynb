{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import string\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "Given (user, music, format(optional)) tuple, predict the rating that the user will give to the music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful fields:\n",
    "# |name       | possible value  | analysis\n",
    "# \"overall\":    1 - 5 (int)\n",
    "# \"verified\":   True / False      (Don't know meaning yet)\n",
    "# \"reviewerID\": \"A1SJL3JBBILJ66\"\n",
    "# \"asin\": \"     B0018CGCR4\"       (music ID)\n",
    "# \"format\":     \" MP3 Music\"      86.44%\n",
    "#               \" Audio CD\"       6.37%\n",
    "#               \"\" (undeclared)   6.95%\n",
    "#               \" Vinyl\"          .2%\n",
    "#               (others)          <.04%\n",
    "# \"reviewText\": \"THANK YOU\"       .09% users doesn't provide reviewText, indcicate as \"\"\n",
    "# \"summary\":    \"Five Stars\"      .002% users doesn't provide summary, indcicate as \"\"\n",
    "# \"image\":      0 (int)           .107% users provide image\n",
    "#                                 indicate number of images provided in the review\n",
    "# \"vote\":       0 (int)           4.48% reviewers are voted by others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training/validation sets... Finish\n",
      "Size of train      set: 140000\n",
      "Size of validation set: 10000\n",
      "Size of test       set: 19781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# constrain: ensure each user/data appear at least 4 times in the training set\n",
    "print('Building training/validation sets... ', end='')\n",
    "\n",
    "f = open(\"./train.json\", 'rt', encoding=\"utf8\")\n",
    "\n",
    "train = [eval(l) for l in f]\n",
    "valid = train[140000:]\n",
    "train = train[:140000]\n",
    "\n",
    "f = open(\"./test.json\", 'rt', encoding=\"utf8\")\n",
    "test = [eval(l) for l in f]\n",
    "\n",
    "print('Finish\\n'\n",
    "      'Size of train      set: %d\\n'\n",
    "      'Size of validation set: %d\\n'\n",
    "      'Size of test       set: %d\\n' % (len(train), len(valid), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.0: Naivest Baseline, Constant\n",
    "Find the constant $\\theta$ that mimize the MSE of the train set as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49839595183673463\n"
     ]
    }
   ],
   "source": [
    "X_t = np.ones((len(train), 1))\n",
    "y_t = [d['overall'] for d in train]\n",
    "X_v = np.ones((len(valid), 1))\n",
    "y_v = [d['overall'] for d in valid]\n",
    "\n",
    "mod = linear_model.LinearRegression()\n",
    "mod.fit(X_t,y_t)\n",
    "\n",
    "print(metrics.mean_squared_error(mod.predict(X_v), y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.1 : Naive Solution 1, Global Average\n",
    "Predict Value = $\\theta_0$ + $\\theta_1$ * (average rating that the user gives out) + $\\theta_2$ * (average rating that the music receives)\n",
    "\n",
    "Use linear regressor to optimize $\\theta_0$, $\\theta_1$ and $\\theta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 5,\n",
       " 'verified': True,\n",
       " 'reviewerID': 'A1SJL3JBBILJ66',\n",
       " 'asin': 'B0018CGCR4',\n",
       " 'reviewText': 'THANK YOU',\n",
       " 'summary': 'Five Stars',\n",
       " 'format': ' MP3 Music',\n",
       " 'vote': 0,\n",
       " 'image': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "users = []\n",
    "items = []\n",
    "for d in train:\n",
    "    r = int(d['overall'])\n",
    "    ratingsPerUser[d['reviewerID']].append(r)\n",
    "    ratingsPerItem[d['asin']].append(r)\n",
    "    users.append(d['reviewerID'])\n",
    "    items.append(d['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRatingsPerUser = defaultdict(int)\n",
    "avgRatingsPerItem = defaultdict(int)\n",
    "for u in ratingsPerUser:\n",
    "    avgRatingsPerUser[u] = np.mean(ratingsPerUser[u])\n",
    "for item in ratingsPerItem:\n",
    "    avgRatingsPerItem[item] = np.mean(ratingsPerItem[item])\n",
    "\n",
    "trainRatings = [int(d['overall']) for d in train]\n",
    "globalAverage = sum(trainRatings) * 1.0 / len(trainRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.700542857142858"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [1,avgRatingsPerUser[datum['reviewerID']],avgRatingsPerItem[datum['asin']]] \n",
    "    return feat\n",
    "X_train = [feature(d) for d in train]\n",
    "y_train = [int(d['overall']) for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod = linear_model.LinearRegression()\n",
    "_ = mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983339575057852\n"
     ]
    }
   ],
   "source": [
    "X_valid = [feature(d) for d in valid]\n",
    "y_valid = [int(d['overall']) for d in valid]\n",
    "# valid_predictions = mod.predict(X_valid)\n",
    "print(metrics.mean_squared_error(mod.predict(X_valid), y_valid))\n",
    "# sum(valid_predictions == y_valid) /len(y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.2: Naive Solution 2, tf-idf\n",
    "Use the similar approach in hw4:\n",
    "\n",
    "Find tf-idf of reviews, then train a Ridge model to predict the rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 5,\n",
       " 'verified': True,\n",
       " 'reviewerID': 'A1SJL3JBBILJ66',\n",
       " 'asin': 'B0018CGCR4',\n",
       " 'reviewText': 'THANK YOU',\n",
       " 'summary': 'Five Stars',\n",
       " 'format': ' MP3 Music',\n",
       " 'vote': 0,\n",
       " 'image': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "totalWords = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train:\n",
    "    t = d['reviewText']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        #w = stemmer.stem(w)\n",
    "        totalWords += 1\n",
    "        wordCount[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76520"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only choose most popular 3000 words to build the feature vector\n",
    "N = 3000\n",
    "words = [w[1] for w in counts[:N]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholeIdf = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train:\n",
    "    t = d['reviewText']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        if not (w in wordSet): continue\n",
    "        wholeIdf[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in wholeIdf.items():\n",
    "    wholeIdf[key] = math.log(10000/value, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureTfIdf(datum):\n",
    "    feat = [0]*len(wordSet)\n",
    "    t = datum['reviewText']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    tf = defaultdict(int)\n",
    "    for w in words:\n",
    "        if not (w in wordSet): continue\n",
    "        tf[w] += 1\n",
    "    for w in words:\n",
    "        if not (w in wordSet): continue\n",
    "        feat[wordId[w]] = tf[w]*wholeIdf[w]\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [featureTfIdf(d) for d in train]\n",
    "y = [d['overall'] for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7151ab99ad67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Solution\n",
    "Sim users give high rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't prove that user will rate a music he'she never listened as the way he/she will rate a listened music.\n",
    "\n",
    "For example, a user will only rate musics he/she like, so he/she rated every music 5 stars.\n",
    "\n",
    "It is possible that our model will predict that the user will give high ratings to all musics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
